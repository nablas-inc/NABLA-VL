{
    "deepspeed": "./examples/zero3.json",
    "output_dir": "./checkpoints",
    "num_train_epochs": 1.0,
    "report_to": "all",
    "per_device_train_batch_size": 2,
    "dataloader_num_workers": 0,
    "dataloader_drop_last": true,
    "gradient_accumulation_steps": 2,
    "group_by_length": true,
    "bf16": true,
    "tf32": true,
    "optim": "adamw_torch",
    "adam_beta2": 0.999,
    "learning_rate": 1e-5,
    "weight_decay": 0.0,
    "lr_scheduler_type": "cosine",
    "warmup_ratio": 0.03,
    "save_only_model": false,
    "save_total_limit": 1,
    "remove_unused_columns": false,
    "logging_steps": 1,
    "model_name_or_path": "nablasinc/NABLA-VL",
    "enable_lazy_init": false,
    "max_length": 9433,
    "dataset_name": "NablaVLDataset",
    "annotation_paths": {
        "./examples/sample_data.json": 1.0
    },
    "image_dir": "./examples/",
    "max_num_samples": 300000,
    "remove_instructions": false,
    "apply_chat_template": true,
    "normalize_type": "inception",
    "use_anyres": true,
    "use_new_line_token": true,
    "factor": 14,
    "max_longer_size": 980,
    "max_pixels": 3841600,
    "enable_flash_attention_2": true,
    "freeze_vision_tower": false,
    "freeze_projector": false,
    "freeze_embedding": false,
    "freeze_llm": false,
    "freeze_lm_head": false,
    "attn_implementation": "flash_attention_2",
    "gradient_checkpointing": true,
    "max_vision_tokens": 6400,
    "num_registers": 24,
    "add_thumbnail": true,
    "num_experts": 1,
    "use_image_token_no": true,
    "dataloader_pin_memory": false
}